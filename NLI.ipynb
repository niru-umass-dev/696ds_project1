{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd59097d-1096-43a1-93fd-baa12ed03478",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "import itertools\n",
    "import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b63aeec-4439-444f-8d56-a47dca2f7e44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# ROBERTA-LARGE-MNLI \n",
    "model = AutoModelForSequenceClassification.from_pretrained('roberta-large-mnli')\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-large-mnli')\n",
    "label_mapping = ['contradiction', 'neutral','entailment']\n",
    "\n",
    "\n",
    "# CROSS-ENCODER NLI-ROBERTA-BASE\n",
    "# model = AutoModelForSequenceClassification.from_pretrained('cross-encoder/nli-roberta-base')\n",
    "# tokenizer = AutoTokenizer.from_pretrained('cross-encoder/nli-roberta-base')\n",
    "# label_mapping = ['contradiction', 'entailment', 'neutral']\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c40a6d84-2119-4557-b9d1-885499c260df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = json.load(open('data/combined_data.json', 'r'))\n",
    "# data = json.load(open('data/combined_data_masked_spacyner_bertscore.json', 'r'))\n",
    "# data = json.load(open('data/combined_data_masked_spacyner_spacysim.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2342b3e0-cb47-40b8-a49c-b2e274f04755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_NLI(sent1, sent2, rev=False):\n",
    "    \n",
    "    if rev == True:\n",
    "        features = tokenizer(sent1,sent2,  padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        features.to(device) \n",
    "    else:    \n",
    "        features = tokenizer(sent2,sent1,  padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        features.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        scores = model(**features).logits\n",
    "        labels = [label_mapping[score_max] for score_max in scores.argmax(dim=1).detach().cpu().numpy()]\n",
    "        \n",
    "        prob = torch.softmax(scores, dim=1).detach().cpu().numpy()\n",
    "            \n",
    "    return labels, prob.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0595f769-1b67-4dc1-89fa-57a84a460fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER METHOD FOR MAIN FUNCTION HELPFUL CONTRAST\n",
    "def cont_helper(a_sum, b_sum, comm_sum,sum_type):\n",
    "\n",
    "    sum_types = []\n",
    "    sent_p1 = []\n",
    "    sent_p2 = []\n",
    "    sent1_ent =[]\n",
    "    sent2_ent = []\n",
    "\n",
    "    count =0\n",
    "    for i in a_sum:\n",
    "        for j in b_sum:\n",
    "\n",
    "            sent_p1.append(i)\n",
    "            sent_p2.append(j)\n",
    "            sent1_ent.append('a')\n",
    "            sent2_ent.append('b')\n",
    "            count+=1\n",
    "\n",
    "    for i in a_sum:\n",
    "        for j in comm_sum:\n",
    "\n",
    "            sent_p1.append(i)\n",
    "            sent_p2.append(j)\n",
    "            sent1_ent.append('a')\n",
    "            sent2_ent.append('comm')\n",
    "            count+=1\n",
    "\n",
    "    for i in b_sum:\n",
    "        for j in comm_sum:\n",
    "\n",
    "            sent_p1.append(i)\n",
    "            sent_p2.append(j)\n",
    "            sent1_ent.append('b')\n",
    "            sent2_ent.append('comm')\n",
    "            count+=1\n",
    "\n",
    "    sum_types += [sum_type] * count\n",
    "\n",
    "    return sent_p1, sent_p2, sent1_ent, sent2_ent, sum_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cb04d1e-ca8b-4caa-b280-70879a913d56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "cont_labels = []\n",
    "cont_probs = []\n",
    "\n",
    "cont_labels_rev = []\n",
    "cont_probs_rev = []\n",
    "\n",
    "sent_pair_1 =[]\n",
    "sent_pair_2 = []\n",
    "sent1_ent =[]\n",
    "sent2_ent = []\n",
    "sample = []\n",
    "sum_type = []\n",
    "\n",
    "for d in range(20,len(data)):\n",
    "    \n",
    "    ################################################################################\n",
    "\n",
    "    # ref summaries just first reference\n",
    "    ref_a_sum = nltk.sent_tokenize(data[d]['refs_a'][0])\n",
    "    ref_b_sum = nltk.sent_tokenize(data[d]['refs_b'][0])\n",
    "    ref_comm_sum = nltk.sent_tokenize(data[d]['refs_comm'][0])\n",
    "\n",
    "    # gen summaries\n",
    "    gen_a_sum = nltk.sent_tokenize(data[d]['gen_a'])\n",
    "    gen_b_sum = nltk.sent_tokenize(data[d]['gen_b'])\n",
    "    gen_comm_sum = nltk.sent_tokenize(data[d]['gen_comm'])\n",
    "\n",
    "    # ref aggregations\n",
    "    ref_sent_p1, ref_sent_p2, ref_sent1_ent, ref_sent2_ent, ref_count = cont_helper(ref_a_sum, ref_b_sum, ref_comm_sum, 'ref')\n",
    "\n",
    "    # gen aggregations\n",
    "    gen_sent_p1, gen_sent_p2, gen_sent1_ent, gen_sent2_ent, gen_count = cont_helper(gen_a_sum, gen_b_sum, gen_comm_sum, 'gen')\n",
    "\n",
    "    sent_pair_1 += ref_sent_p1 + gen_sent_p1\n",
    "    sent_pair_2 += ref_sent_p2 + gen_sent_p2\n",
    "    sent1_ent += ref_sent1_ent + gen_sent1_ent\n",
    "    sent2_ent += ref_sent2_ent + gen_sent2_ent\n",
    "    sum_type += ref_count + gen_count\n",
    "\n",
    "    sample += [d] * len(ref_count + gen_count)\n",
    "\n",
    "    cont_label, cont_prob = compute_NLI(ref_sent_p1 + gen_sent_p1, ref_sent_p2 + gen_sent_p2)\n",
    "\n",
    "    cont_label_rev, cont_prob_rev = compute_NLI(ref_sent_p1 + gen_sent_p1, ref_sent_p2 + gen_sent_p2, rev=True)\n",
    "\n",
    "    cont_labels += cont_label\n",
    "    cont_probs.append(cont_prob)\n",
    "\n",
    "    cont_labels_rev += cont_label_rev\n",
    "    cont_probs_rev.append(cont_prob_rev)\n",
    "\n",
    "    print(d-20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5015fc0c-93a3-40ea-a6c2-6fed37ed811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = [j for i in cont_probs for j in np.array(i)[:,label_mapping.index(\"contradiction\")]]\n",
    "neut = [j for i in cont_probs for j in np.array(i)[:,label_mapping.index(\"neutral\")]]\n",
    "ent = [j for i in cont_probs for j in np.array(i)[:,label_mapping.index(\"entailment\")]]\n",
    "cont_rev = [j for i in cont_probs_rev for j in np.array(i)[:,label_mapping.index(\"contradiction\")]]\n",
    "neut_rev = [j for i in cont_probs_rev for j in np.array(i)[:,label_mapping.index(\"neutral\")]]\n",
    "ent_rev = [j for i in cont_probs_rev for j in np.array(i)[:,label_mapping.index(\"entailment\")]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41c8dbee-f188-4b76-b457-aa1fdf202d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_df = pd.DataFrame(\n",
    "    {'Sentence1': sent_pair_1,\n",
    "     'Sentence2': sent_pair_2,\n",
    "     'Sent1_entity': sent1_ent,\n",
    "     'Sent2_entity': sent2_ent,\n",
    "     'Sample': sample,\n",
    "     '1_2_neut':  neut,\n",
    "     '1_2_cont': cont,\n",
    "     '1_2_ent': ent,\n",
    "     '1_2_Label': cont_labels,\n",
    "     '2_1_neut': neut_rev,\n",
    "     '2_1_cont': cont_rev,\n",
    "     '2_1_ent': ent_rev, \n",
    "     '2_1_Label': cont_labels_rev,\n",
    "     'Type': sum_type\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13b22e12-c523-4efa-bc2d-f185414ec0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER METHOD FOR MAIN FUNCTION POPULAR OPINION FACTUAL CONSISTENCY\n",
    "def fact_helper(source_a, source_b, a_sum, b_sum, comm_sum,sum_type):\n",
    "\n",
    "    sum_types = []\n",
    "    sent_p1 = []\n",
    "    sent_p2 = []\n",
    "    sent1_source =[]\n",
    "    sent1_source_ent =[]\n",
    "    sent2_ent = []\n",
    "\n",
    "    count =0\n",
    "    for i in range(len(source_a)):\n",
    "        for j in source_a[i]:\n",
    "            for k in a_sum:\n",
    "\n",
    "                sent_p1.append(j)\n",
    "                sent_p2.append(k)\n",
    "                sent1_source.append(i)\n",
    "                sent1_source_ent.append('a')\n",
    "                sent2_ent.append('a')\n",
    "                count+=1\n",
    "\n",
    "    for i in range(len(source_a)):\n",
    "        for j in source_a[i]:\n",
    "            for k in comm_sum:\n",
    "\n",
    "                sent_p1.append(j)\n",
    "                sent_p2.append(k)\n",
    "                sent1_source.append(i)\n",
    "                sent1_source_ent.append('a')\n",
    "                sent2_ent.append('comm')\n",
    "                count+=1\n",
    "\n",
    "    for i in range(len(source_b)):\n",
    "        for j in source_b[i]:\n",
    "            for k in b_sum:\n",
    "\n",
    "                sent_p1.append(j)\n",
    "                sent_p2.append(k)\n",
    "                sent1_source.append(i)\n",
    "                sent1_source_ent.append('b')\n",
    "                sent2_ent.append('b')\n",
    "                count+=1\n",
    "\n",
    "    for i in range(len(source_b)):\n",
    "        for j in source_b[i]:\n",
    "            for k in comm_sum:\n",
    "\n",
    "                sent_p1.append(j)\n",
    "                sent_p2.append(k)\n",
    "                sent1_source.append(i)\n",
    "                sent1_source_ent.append('b')\n",
    "                sent2_ent.append('comm')\n",
    "                count+=1\n",
    "\n",
    "    sum_types += [sum_type] * count\n",
    "\n",
    "    return sent_p1, sent_p2, sent1_source, sent1_source_ent, sent2_ent, sum_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef0e40d9-7716-49bd-9803-fb03891d10cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "fact_labels = []\n",
    "fact_probs = []\n",
    "sent_pair_1 =[]\n",
    "sent_pair_2 = []\n",
    "sent1_source =[]\n",
    "sent1_source_ent =[]\n",
    "sent2_ent = []\n",
    "sample = []\n",
    "sum_type = []\n",
    "\n",
    "for d in range(20,len(data)):\n",
    "\n",
    "    # source reviews \n",
    "    source_a = [nltk.sent_tokenize(i) for i in data[d]['source_reviews_a']]\n",
    "    source_b = [nltk.sent_tokenize(i) for i in data[d]['source_reviews_b']]\n",
    "\n",
    "    # ref summaries just first reference\n",
    "    ref_a_sum = nltk.sent_tokenize(data[d]['refs_a'][0])\n",
    "    ref_b_sum = nltk.sent_tokenize(data[d]['refs_b'][0])\n",
    "    ref_comm_sum = nltk.sent_tokenize(data[d]['refs_comm'][0])\n",
    "\n",
    "    # ref aggregations\n",
    "    ref_sent_p1, ref_sent_p2, ref_sent1_source, ref_sent1_source_ent,ref_sent2_ent, ref_count = fact_helper(source_a, source_b, ref_a_sum, ref_b_sum, ref_comm_sum, 'ref')\n",
    "\n",
    "    sent_pair_1 += ref_sent_p1 \n",
    "    sent_pair_2 += ref_sent_p2 \n",
    "    sent1_source += ref_sent1_source \n",
    "    sent1_source_ent += ref_sent1_source_ent\n",
    "    sent2_ent += ref_sent2_ent \n",
    "    sum_type += ref_count \n",
    "\n",
    "    sample += [d] * len(ref_count)\n",
    "\n",
    "    fact_label, fact_prob = compute_NLI(ref_sent_p1,ref_sent_p2)\n",
    "\n",
    "    fact_labels += fact_label\n",
    "    fact_probs.append(fact_prob)\n",
    "\n",
    "    print(d-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "835b0f23-8649-42f8-a074-394f23f5fd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "fact_labels_gen = []\n",
    "fact_probs_gen = []\n",
    "sent_pair_1_gen =[]\n",
    "sent_pair_2_gen = []\n",
    "sent1_source_gen =[]\n",
    "sent1_source_ent_gen =[]\n",
    "sent2_ent_gen = []\n",
    "sample_gen = []\n",
    "sum_type_gen = []\n",
    "\n",
    "for d in range(20,len(data)):\n",
    "\n",
    "    # source reviews \n",
    "    source_a = [nltk.sent_tokenize(i) for i in data[d]['source_reviews_a']]\n",
    "    source_b = [nltk.sent_tokenize(i) for i in data[d]['source_reviews_b']]\n",
    "\n",
    "    # gen summaries\n",
    "    gen_a_sum = nltk.sent_tokenize(data[d]['gen_a'])\n",
    "    gen_b_sum = nltk.sent_tokenize(data[d]['gen_b'])\n",
    "    gen_comm_sum = nltk.sent_tokenize(data[d]['gen_comm'])\n",
    "\n",
    "    # gen aggregations\n",
    "    gen_sent_p1, gen_sent_p2, gen_sent1_source, gen_sent1_source_ent, gen_sent2_ent, gen_count = fact_helper(source_a, source_b, gen_a_sum, gen_b_sum, gen_comm_sum, 'gen')\n",
    "\n",
    "    sent_pair_1_gen +=  gen_sent_p1\n",
    "    sent_pair_2_gen +=  gen_sent_p2\n",
    "    sent1_source_gen +=  gen_sent1_source\n",
    "    sent1_source_ent_gen +=  gen_sent1_source_ent\n",
    "    sent2_ent_gen +=  gen_sent2_ent\n",
    "    sum_type_gen += gen_count\n",
    "\n",
    "    sample_gen += [d] * len(gen_count)\n",
    "\n",
    "    fact_label_gen, fact_prob_gen = compute_NLI(gen_sent_p1, gen_sent_p2)\n",
    "\n",
    "    fact_labels_gen += fact_label_gen\n",
    "    fact_probs_gen.append(fact_prob_gen)\n",
    "\n",
    "    print(d-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b212a335-9449-4b2a-9fef-cfe2a6b6b927",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = [j for i in fact_probs for j in np.array(i)[:,label_mapping.index(\"contradiction\")]]\n",
    "neut = [j for i in fact_probs for j in np.array(i)[:,label_mapping.index(\"neutral\")]]\n",
    "ent = [j for i in fact_probs for j in np.array(i)[:,label_mapping.index(\"entailment\")]]\n",
    "cont_gen = [j for i in fact_probs_gen for j in np.array(i)[:,label_mapping.index(\"contradiction\")]]\n",
    "neut_gen = [j for i in fact_probs_gen for j in np.array(i)[:,label_mapping.index(\"neutral\")]]\n",
    "ent_gen = [j for i in fact_probs_gen for j in np.array(i)[:,label_mapping.index(\"entailment\")]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bfd8945-0fb9-4a0e-856b-55f2f62915c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_pop_df = pd.DataFrame(\n",
    "    {'Sentence1': sent_pair_1 + sent_pair_1_gen,\n",
    "     'Sentence2': sent_pair_2 + sent_pair_2_gen,\n",
    "     'Sample': sample + sample_gen,\n",
    "     'Sent1_source': sent1_source + sent1_source_gen,\n",
    "     'Sent1_source_entity': sent1_source_ent + sent1_source_ent_gen,\n",
    "     'Sent2_entity': sent2_ent + sent2_ent_gen,\n",
    "     '1_2_neut':  neut + neut_gen,\n",
    "     '1_2_cont': cont + cont_gen,\n",
    "     '1_2_ent': ent + ent_gen,\n",
    "     'Label': fact_labels +fact_labels_gen,\n",
    "     'Type': sum_type + sum_type_gen\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86497a90-0999-4ed7-91e9-2469161294fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence1</th>\n",
       "      <th>Sentence2</th>\n",
       "      <th>Sample</th>\n",
       "      <th>Sent1_source</th>\n",
       "      <th>Sent1_source_entity</th>\n",
       "      <th>Sent2_entity</th>\n",
       "      <th>1_2_neut</th>\n",
       "      <th>1_2_cont</th>\n",
       "      <th>1_2_ent</th>\n",
       "      <th>Label</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our company has rented conference rooms and he...</td>\n",
       "      <td>The hotel has conference rooms available to re...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>0.997668</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>neutral</td>\n",
       "      <td>ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our company has rented conference rooms and he...</td>\n",
       "      <td>The location of this hotel makes it easy to ac...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>0.997710</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>neutral</td>\n",
       "      <td>ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Our company has rented conference rooms and he...</td>\n",
       "      <td>The rooms are a good size and well decorated.</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>0.997670</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>neutral</td>\n",
       "      <td>ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Our company has rented conference rooms and he...</td>\n",
       "      <td>The bathroom in the hotel was large and with a...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>0.997793</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>neutral</td>\n",
       "      <td>ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Our company has rented conference rooms and he...</td>\n",
       "      <td>Small touches like a chocolate on the pillow a...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>0.991852</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>neutral</td>\n",
       "      <td>ref</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentence1  \\\n",
       "0  Our company has rented conference rooms and he...   \n",
       "1  Our company has rented conference rooms and he...   \n",
       "2  Our company has rented conference rooms and he...   \n",
       "3  Our company has rented conference rooms and he...   \n",
       "4  Our company has rented conference rooms and he...   \n",
       "\n",
       "                                           Sentence2  Sample  Sent1_source  \\\n",
       "0  The hotel has conference rooms available to re...      20             0   \n",
       "1  The location of this hotel makes it easy to ac...      20             0   \n",
       "2      The rooms are a good size and well decorated.      20             0   \n",
       "3  The bathroom in the hotel was large and with a...      20             0   \n",
       "4  Small touches like a chocolate on the pillow a...      20             0   \n",
       "\n",
       "  Sent1_source_entity Sent2_entity  1_2_neut  1_2_cont   1_2_ent    Label Type  \n",
       "0                   a            a  0.997668  0.001168  0.001164  neutral  ref  \n",
       "1                   a            a  0.997710  0.001137  0.001153  neutral  ref  \n",
       "2                   a            a  0.997670  0.000670  0.001660  neutral  ref  \n",
       "3                   a            a  0.997793  0.000786  0.001421  neutral  ref  \n",
       "4                   a            a  0.991852  0.004484  0.003664  neutral  ref  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_pop_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18d2df7e-6a59-4ebe-822d-f7d7de5e218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_df.to_csv('contrast.csv', index = None, header=True) \n",
    "fact_pop_df.to_csv('factuality_popular.csv', index = None, header=True) \n",
    "\n",
    "# cont_df.to_csv('contrast_mask_bertscore.csv', index = None, header=True) \n",
    "# fact_pop_df.to_csv('factuality_popular_mask_bertscore.csv', index = None, header=True) \n",
    "\n",
    "# cont_df.to_csv('contrast_mask_spacysim.csv', index = None, header=True) \n",
    "# fact_pop_df.to_csv('factuality_popular_mask_spacysim.csv', index = None, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b66e35a-818a-47d9-afa6-0cd33e3ab2d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.conda-ds696-project)",
   "language": "python",
   "name": "conda-env-.conda-ds696-project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
