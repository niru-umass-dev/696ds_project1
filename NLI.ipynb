{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd59097d-1096-43a1-93fd-baa12ed03478",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "import itertools\n",
    "import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b63aeec-4439-444f-8d56-a47dca2f7e44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/dduong_umass_edu/.conda/envs/ds696-project/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# # ROBERTA-LARGE-MNLI \n",
    "# model = AutoModelForSequenceClassification.from_pretrained('roberta-large-mnli')\n",
    "# tokenizer = AutoTokenizer.from_pretrained('roberta-large-mnli')\n",
    "# label_mapping = ['contradiction', 'neutral','entailment']\n",
    "\n",
    "# # CROSS-ENCODER NLI-ROBERTA-BASE\n",
    "# # model = AutoModelForSequenceClassification.from_pretrained('cross-encoder/nli-roberta-base')\n",
    "# # tokenizer = AutoTokenizer.from_pretrained('cross-encoder/nli-roberta-base')\n",
    "# # label_mapping = ['contradiction', 'entailment', 'neutral']\n",
    "\n",
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model = model.to(device)\n",
    "\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\",model='roberta-large-mnli' ,return_all_scores=True, device = 0)\n",
    "# pipe = pipeline(\"text-classification\",model='cross-encoder/nli-roberta-base' ,return_all_scores=True, device = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c40a6d84-2119-4557-b9d1-885499c260df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = json.load(open('data/combined_data.json', 'r'))\n",
    "# data = json.load(open('data/combined_data_masked_spacyner_bertscore.json', 'r'))\n",
    "# data = json.load(open('data/combined_data_masked_spacyner_spacysim.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2342b3e0-cb47-40b8-a49c-b2e274f04755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_NLI(sent1, sent2, rev=False):\n",
    "    \n",
    "#     if rev == True:\n",
    "#         features = tokenizer(sent1,sent2,  padding=True, truncation=True, return_tensors=\"pt\")\n",
    "#         features.to(device) \n",
    "#     else:    \n",
    "#         features = tokenizer(sent2,sent1,  padding=True, truncation=True, return_tensors=\"pt\")\n",
    "#         features.to(device)\n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         scores = model(**features).logits\n",
    "#         labels = [label_mapping[score_max] for score_max in scores.argmax(dim=1).detach().cpu().numpy()]\n",
    "        \n",
    "#         prob = torch.softmax(scores, dim=1).detach().cpu().numpy()\n",
    "            \n",
    "#     return labels, prob.tolist()\n",
    "\n",
    "label_mapping = ['contradiction', 'neutral','entailment']\n",
    "\n",
    "def compute_NLI(sent1, sent2, rev=False):\n",
    "    \n",
    "    labels = []\n",
    "    prob = []\n",
    "    \n",
    "    combined_list = []\n",
    "    \n",
    "    if rev == True:\n",
    "        for s1, s2 in zip(sent2, sent1):\n",
    "            combined_list.append(s1 + ' ' + s2)\n",
    "    else:    \n",
    "        for s1, s2 in zip(sent1, sent2):\n",
    "            combined_list.append(s1 + ' ' + s2)\n",
    "            \n",
    "    \n",
    "    results = pipe(combined_list)\n",
    "    \n",
    "    for i in results:\n",
    "        result = {d['label']: d['score'] for d in i}\n",
    "        labels.append(max(result, key=result.get))\n",
    "        prob.append(list(result.values()))\n",
    "\n",
    "            \n",
    "    return labels, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0595f769-1b67-4dc1-89fa-57a84a460fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER METHOD FOR MAIN FUNCTION HELPFUL CONTRAST\n",
    "def cont_helper(a_sum, b_sum, comm_sum,sum_type):\n",
    "\n",
    "    sum_types = []\n",
    "    sent_p1 = []\n",
    "    sent_p2 = []\n",
    "    sent1_ent =[]\n",
    "    sent2_ent = []\n",
    "\n",
    "    count =0\n",
    "    for i in a_sum:\n",
    "        for j in b_sum:\n",
    "\n",
    "            sent_p1.append(i)\n",
    "            sent_p2.append(j)\n",
    "            sent1_ent.append('a')\n",
    "            sent2_ent.append('b')\n",
    "            count+=1\n",
    "\n",
    "    for i in a_sum:\n",
    "        for j in comm_sum:\n",
    "\n",
    "            sent_p1.append(i)\n",
    "            sent_p2.append(j)\n",
    "            sent1_ent.append('a')\n",
    "            sent2_ent.append('comm')\n",
    "            count+=1\n",
    "\n",
    "    for i in b_sum:\n",
    "        for j in comm_sum:\n",
    "\n",
    "            sent_p1.append(i)\n",
    "            sent_p2.append(j)\n",
    "            sent1_ent.append('b')\n",
    "            sent2_ent.append('comm')\n",
    "            count+=1\n",
    "\n",
    "    sum_types += [sum_type] * count\n",
    "\n",
    "    return sent_p1, sent_p2, sent1_ent, sent2_ent, sum_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cb04d1e-ca8b-4caa-b280-70879a913d56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dduong_umass_edu/.conda/envs/ds696-project/lib/python3.9/site-packages/transformers/pipelines/base.py:1070: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "cont_labels = []\n",
    "cont_probs = []\n",
    "\n",
    "cont_labels_rev = []\n",
    "cont_probs_rev = []\n",
    "\n",
    "sent_pair_1 =[]\n",
    "sent_pair_2 = []\n",
    "sent1_ent =[]\n",
    "sent2_ent = []\n",
    "sample = []\n",
    "sum_type = []\n",
    "\n",
    "for d in range(20,len(data)):\n",
    "    \n",
    "    ################################################################################\n",
    "\n",
    "    # ref summaries just first reference\n",
    "    ref_a_sum = nltk.sent_tokenize(data[d]['refs_a'][0])\n",
    "    ref_b_sum = nltk.sent_tokenize(data[d]['refs_b'][0])\n",
    "    ref_comm_sum = nltk.sent_tokenize(data[d]['refs_comm'][0])\n",
    "\n",
    "    # gen summaries\n",
    "    gen_a_sum = nltk.sent_tokenize(data[d]['gen_a'])\n",
    "    gen_b_sum = nltk.sent_tokenize(data[d]['gen_b'])\n",
    "    gen_comm_sum = nltk.sent_tokenize(data[d]['gen_comm'])\n",
    "\n",
    "    # ref aggregations\n",
    "    ref_sent_p1, ref_sent_p2, ref_sent1_ent, ref_sent2_ent, ref_count = cont_helper(ref_a_sum, ref_b_sum, ref_comm_sum, 'ref')\n",
    "\n",
    "    # gen aggregations\n",
    "    gen_sent_p1, gen_sent_p2, gen_sent1_ent, gen_sent2_ent, gen_count = cont_helper(gen_a_sum, gen_b_sum, gen_comm_sum, 'gen')\n",
    "\n",
    "    sent_pair_1 += ref_sent_p1 + gen_sent_p1\n",
    "    sent_pair_2 += ref_sent_p2 + gen_sent_p2\n",
    "    sent1_ent += ref_sent1_ent + gen_sent1_ent\n",
    "    sent2_ent += ref_sent2_ent + gen_sent2_ent\n",
    "    sum_type += ref_count + gen_count\n",
    "\n",
    "    sample += [d] * len(ref_count + gen_count)\n",
    "\n",
    "    cont_label, cont_prob = compute_NLI(ref_sent_p1 + gen_sent_p1, ref_sent_p2 + gen_sent_p2)\n",
    "\n",
    "    cont_label_rev, cont_prob_rev = compute_NLI(ref_sent_p1 + gen_sent_p1, ref_sent_p2 + gen_sent_p2, rev=True)\n",
    "\n",
    "    cont_labels += cont_label\n",
    "    cont_probs.append(cont_prob)\n",
    "\n",
    "    cont_labels_rev += cont_label_rev\n",
    "    cont_probs_rev.append(cont_prob_rev)\n",
    "\n",
    "    print(d-20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5015fc0c-93a3-40ea-a6c2-6fed37ed811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = [j for i in cont_probs for j in np.array(i)[:,label_mapping.index(\"contradiction\")]]\n",
    "neut = [j for i in cont_probs for j in np.array(i)[:,label_mapping.index(\"neutral\")]]\n",
    "ent = [j for i in cont_probs for j in np.array(i)[:,label_mapping.index(\"entailment\")]]\n",
    "cont_rev = [j for i in cont_probs_rev for j in np.array(i)[:,label_mapping.index(\"contradiction\")]]\n",
    "neut_rev = [j for i in cont_probs_rev for j in np.array(i)[:,label_mapping.index(\"neutral\")]]\n",
    "ent_rev = [j for i in cont_probs_rev for j in np.array(i)[:,label_mapping.index(\"entailment\")]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41c8dbee-f188-4b76-b457-aa1fdf202d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_df = pd.DataFrame(\n",
    "    {'Sentence1': sent_pair_1,\n",
    "     'Sentence2': sent_pair_2,\n",
    "     'Sent1_entity': sent1_ent,\n",
    "     'Sent2_entity': sent2_ent,\n",
    "     'Sample': sample,\n",
    "     '1_2_neut':  neut,\n",
    "     '1_2_cont': cont,\n",
    "     '1_2_ent': ent,\n",
    "     '1_2_Label': cont_labels,\n",
    "     '2_1_neut': neut_rev,\n",
    "     '2_1_cont': cont_rev,\n",
    "     '2_1_ent': ent_rev, \n",
    "     '2_1_Label': cont_labels_rev,\n",
    "     'Type': sum_type\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3faa5aa-9171-4568-b00d-c24c627ff232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence1</th>\n",
       "      <th>Sentence2</th>\n",
       "      <th>Sent1_entity</th>\n",
       "      <th>Sent2_entity</th>\n",
       "      <th>Sample</th>\n",
       "      <th>1_2_neut</th>\n",
       "      <th>1_2_cont</th>\n",
       "      <th>1_2_ent</th>\n",
       "      <th>1_2_Label</th>\n",
       "      <th>2_1_neut</th>\n",
       "      <th>2_1_cont</th>\n",
       "      <th>2_1_ent</th>\n",
       "      <th>2_1_Label</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The hotel has conference rooms available to re...</td>\n",
       "      <td>The hotel is especially memorable during a win...</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>20</td>\n",
       "      <td>0.996581</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0.985133</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.013463</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The hotel has conference rooms available to re...</td>\n",
       "      <td>The room was okay but on the small side includ...</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>20</td>\n",
       "      <td>0.997398</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0.987318</td>\n",
       "      <td>0.005042</td>\n",
       "      <td>0.007640</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The hotel has conference rooms available to re...</td>\n",
       "      <td>After upgrading rooms to a suite this was abso...</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>20</td>\n",
       "      <td>0.996554</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0.988690</td>\n",
       "      <td>0.005756</td>\n",
       "      <td>0.005554</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The hotel has conference rooms available to re...</td>\n",
       "      <td>Whilst the breakfast and dinners are both quit...</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>20</td>\n",
       "      <td>0.994297</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0.980109</td>\n",
       "      <td>0.007115</td>\n",
       "      <td>0.012776</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The hotel has conference rooms available to re...</td>\n",
       "      <td>But a coffee maker and coffee was not free of ...</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>20</td>\n",
       "      <td>0.986599</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0.961168</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>0.034178</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>ref</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentence1  \\\n",
       "0  The hotel has conference rooms available to re...   \n",
       "1  The hotel has conference rooms available to re...   \n",
       "2  The hotel has conference rooms available to re...   \n",
       "3  The hotel has conference rooms available to re...   \n",
       "4  The hotel has conference rooms available to re...   \n",
       "\n",
       "                                           Sentence2 Sent1_entity  \\\n",
       "0  The hotel is especially memorable during a win...            a   \n",
       "1  The room was okay but on the small side includ...            a   \n",
       "2  After upgrading rooms to a suite this was abso...            a   \n",
       "3  Whilst the breakfast and dinners are both quit...            a   \n",
       "4  But a coffee maker and coffee was not free of ...            a   \n",
       "\n",
       "  Sent2_entity  Sample  1_2_neut  1_2_cont   1_2_ent 1_2_Label  2_1_neut  \\\n",
       "0            b      20  0.996581  0.001241  0.002178   NEUTRAL  0.985133   \n",
       "1            b      20  0.997398  0.001197  0.001405   NEUTRAL  0.987318   \n",
       "2            b      20  0.996554  0.002648  0.000798   NEUTRAL  0.988690   \n",
       "3            b      20  0.994297  0.003784  0.001919   NEUTRAL  0.980109   \n",
       "4            b      20  0.986599  0.009013  0.004388   NEUTRAL  0.961168   \n",
       "\n",
       "   2_1_cont   2_1_ent 2_1_Label Type  \n",
       "0  0.001404  0.013463   NEUTRAL  ref  \n",
       "1  0.005042  0.007640   NEUTRAL  ref  \n",
       "2  0.005756  0.005554   NEUTRAL  ref  \n",
       "3  0.007115  0.012776   NEUTRAL  ref  \n",
       "4  0.004654  0.034178   NEUTRAL  ref  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13b22e12-c523-4efa-bc2d-f185414ec0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER METHOD FOR MAIN FUNCTION POPULAR OPINION FACTUAL CONSISTENCY\n",
    "def fact_helper(source_a, source_b, a_sum, b_sum, comm_sum,sum_type):\n",
    "\n",
    "    sum_types = []\n",
    "    sent_p1 = []\n",
    "    sent_p2 = []\n",
    "    sent1_source =[]\n",
    "    sent1_source_ent =[]\n",
    "    sent2_ent = []\n",
    "\n",
    "    count =0\n",
    "    for i in range(len(source_a)):\n",
    "        for j in source_a[i]:\n",
    "            for k in a_sum:\n",
    "\n",
    "                sent_p1.append(j)\n",
    "                sent_p2.append(k)\n",
    "                sent1_source.append(i)\n",
    "                sent1_source_ent.append('a')\n",
    "                sent2_ent.append('a')\n",
    "                count+=1\n",
    "\n",
    "    for i in range(len(source_a)):\n",
    "        for j in source_a[i]:\n",
    "            for k in comm_sum:\n",
    "\n",
    "                sent_p1.append(j)\n",
    "                sent_p2.append(k)\n",
    "                sent1_source.append(i)\n",
    "                sent1_source_ent.append('a')\n",
    "                sent2_ent.append('comm')\n",
    "                count+=1\n",
    "\n",
    "    for i in range(len(source_b)):\n",
    "        for j in source_b[i]:\n",
    "            for k in b_sum:\n",
    "\n",
    "                sent_p1.append(j)\n",
    "                sent_p2.append(k)\n",
    "                sent1_source.append(i)\n",
    "                sent1_source_ent.append('b')\n",
    "                sent2_ent.append('b')\n",
    "                count+=1\n",
    "\n",
    "    for i in range(len(source_b)):\n",
    "        for j in source_b[i]:\n",
    "            for k in comm_sum:\n",
    "\n",
    "                sent_p1.append(j)\n",
    "                sent_p2.append(k)\n",
    "                sent1_source.append(i)\n",
    "                sent1_source_ent.append('b')\n",
    "                sent2_ent.append('comm')\n",
    "                count+=1\n",
    "\n",
    "    sum_types += [sum_type] * count\n",
    "\n",
    "    return sent_p1, sent_p2, sent1_source, sent1_source_ent, sent2_ent, sum_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef0e40d9-7716-49bd-9803-fb03891d10cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dduong_umass_edu/.conda/envs/ds696-project/lib/python3.9/site-packages/transformers/pipelines/base.py:1070: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "fact_labels = []\n",
    "fact_probs = []\n",
    "sent_pair_1 =[]\n",
    "sent_pair_2 = []\n",
    "sent1_source =[]\n",
    "sent1_source_ent =[]\n",
    "sent2_ent = []\n",
    "sample = []\n",
    "sum_type = []\n",
    "\n",
    "for d in range(20,len(data)):\n",
    "\n",
    "    # source reviews \n",
    "    source_a = [nltk.sent_tokenize(i) for i in data[d]['source_reviews_a']]\n",
    "    source_b = [nltk.sent_tokenize(i) for i in data[d]['source_reviews_b']]\n",
    "\n",
    "    # ref summaries just first reference\n",
    "    ref_a_sum = nltk.sent_tokenize(data[d]['refs_a'][0])\n",
    "    ref_b_sum = nltk.sent_tokenize(data[d]['refs_b'][0])\n",
    "    ref_comm_sum = nltk.sent_tokenize(data[d]['refs_comm'][0])\n",
    "\n",
    "    # ref aggregations\n",
    "    ref_sent_p1, ref_sent_p2, ref_sent1_source, ref_sent1_source_ent,ref_sent2_ent, ref_count = fact_helper(source_a, source_b, ref_a_sum, ref_b_sum, ref_comm_sum, 'ref')\n",
    "\n",
    "    sent_pair_1 += ref_sent_p1 \n",
    "    sent_pair_2 += ref_sent_p2 \n",
    "    sent1_source += ref_sent1_source \n",
    "    sent1_source_ent += ref_sent1_source_ent\n",
    "    sent2_ent += ref_sent2_ent \n",
    "    sum_type += ref_count \n",
    "\n",
    "    sample += [d] * len(ref_count)\n",
    "\n",
    "    fact_label, fact_prob = compute_NLI(ref_sent_p1,ref_sent_p2)\n",
    "\n",
    "    fact_labels += fact_label\n",
    "    fact_probs.append(fact_prob)\n",
    "\n",
    "    print(d-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "835b0f23-8649-42f8-a074-394f23f5fd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "fact_labels_gen = []\n",
    "fact_probs_gen = []\n",
    "sent_pair_1_gen =[]\n",
    "sent_pair_2_gen = []\n",
    "sent1_source_gen =[]\n",
    "sent1_source_ent_gen =[]\n",
    "sent2_ent_gen = []\n",
    "sample_gen = []\n",
    "sum_type_gen = []\n",
    "\n",
    "for d in range(20,len(data)):\n",
    "\n",
    "    # source reviews \n",
    "    source_a = [nltk.sent_tokenize(i) for i in data[d]['source_reviews_a']]\n",
    "    source_b = [nltk.sent_tokenize(i) for i in data[d]['source_reviews_b']]\n",
    "\n",
    "    # gen summaries\n",
    "    gen_a_sum = nltk.sent_tokenize(data[d]['gen_a'])\n",
    "    gen_b_sum = nltk.sent_tokenize(data[d]['gen_b'])\n",
    "    gen_comm_sum = nltk.sent_tokenize(data[d]['gen_comm'])\n",
    "\n",
    "    # gen aggregations\n",
    "    gen_sent_p1, gen_sent_p2, gen_sent1_source, gen_sent1_source_ent, gen_sent2_ent, gen_count = fact_helper(source_a, source_b, gen_a_sum, gen_b_sum, gen_comm_sum, 'gen')\n",
    "\n",
    "    sent_pair_1_gen +=  gen_sent_p1\n",
    "    sent_pair_2_gen +=  gen_sent_p2\n",
    "    sent1_source_gen +=  gen_sent1_source\n",
    "    sent1_source_ent_gen +=  gen_sent1_source_ent\n",
    "    sent2_ent_gen +=  gen_sent2_ent\n",
    "    sum_type_gen += gen_count\n",
    "\n",
    "    sample_gen += [d] * len(gen_count)\n",
    "\n",
    "    fact_label_gen, fact_prob_gen = compute_NLI(gen_sent_p1, gen_sent_p2)\n",
    "\n",
    "    fact_labels_gen += fact_label_gen\n",
    "    fact_probs_gen.append(fact_prob_gen)\n",
    "\n",
    "    print(d-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b212a335-9449-4b2a-9fef-cfe2a6b6b927",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = [j for i in fact_probs for j in np.array(i)[:,label_mapping.index(\"contradiction\")]]\n",
    "neut = [j for i in fact_probs for j in np.array(i)[:,label_mapping.index(\"neutral\")]]\n",
    "ent = [j for i in fact_probs for j in np.array(i)[:,label_mapping.index(\"entailment\")]]\n",
    "cont_gen = [j for i in fact_probs_gen for j in np.array(i)[:,label_mapping.index(\"contradiction\")]]\n",
    "neut_gen = [j for i in fact_probs_gen for j in np.array(i)[:,label_mapping.index(\"neutral\")]]\n",
    "ent_gen = [j for i in fact_probs_gen for j in np.array(i)[:,label_mapping.index(\"entailment\")]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bfd8945-0fb9-4a0e-856b-55f2f62915c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_pop_df = pd.DataFrame(\n",
    "    {'Sentence1': sent_pair_1 + sent_pair_1_gen,\n",
    "     'Sentence2': sent_pair_2 + sent_pair_2_gen,\n",
    "     'Sample': sample + sample_gen,\n",
    "     'Sent1_source': sent1_source + sent1_source_gen,\n",
    "     'Sent1_source_entity': sent1_source_ent + sent1_source_ent_gen,\n",
    "     'Sent2_entity': sent2_ent + sent2_ent_gen,\n",
    "     '1_2_neut':  neut + neut_gen,\n",
    "     '1_2_cont': cont + cont_gen,\n",
    "     '1_2_ent': ent + ent_gen,\n",
    "     'Label': fact_labels +fact_labels_gen,\n",
    "     'Type': sum_type + sum_type_gen\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86497a90-0999-4ed7-91e9-2469161294fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence1</th>\n",
       "      <th>Sentence2</th>\n",
       "      <th>Sample</th>\n",
       "      <th>Sent1_source</th>\n",
       "      <th>Sent1_source_entity</th>\n",
       "      <th>Sent2_entity</th>\n",
       "      <th>1_2_neut</th>\n",
       "      <th>1_2_cont</th>\n",
       "      <th>1_2_ent</th>\n",
       "      <th>Label</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our company has rented conference rooms and he...</td>\n",
       "      <td>The hotel has conference rooms available to re...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>0.028312</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.970860</td>\n",
       "      <td>ENTAILMENT</td>\n",
       "      <td>ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our company has rented conference rooms and he...</td>\n",
       "      <td>The location of this hotel makes it easy to ac...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>0.997530</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Our company has rented conference rooms and he...</td>\n",
       "      <td>The rooms are a good size and well decorated.</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>0.997514</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Our company has rented conference rooms and he...</td>\n",
       "      <td>The bathroom in the hotel was large and with a...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>0.997635</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Our company has rented conference rooms and he...</td>\n",
       "      <td>Small touches like a chocolate on the pillow a...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>0.997635</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>ref</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentence1  \\\n",
       "0  Our company has rented conference rooms and he...   \n",
       "1  Our company has rented conference rooms and he...   \n",
       "2  Our company has rented conference rooms and he...   \n",
       "3  Our company has rented conference rooms and he...   \n",
       "4  Our company has rented conference rooms and he...   \n",
       "\n",
       "                                           Sentence2  Sample  Sent1_source  \\\n",
       "0  The hotel has conference rooms available to re...      20             0   \n",
       "1  The location of this hotel makes it easy to ac...      20             0   \n",
       "2      The rooms are a good size and well decorated.      20             0   \n",
       "3  The bathroom in the hotel was large and with a...      20             0   \n",
       "4  Small touches like a chocolate on the pillow a...      20             0   \n",
       "\n",
       "  Sent1_source_entity Sent2_entity  1_2_neut  1_2_cont   1_2_ent       Label  \\\n",
       "0                   a            a  0.028312  0.000828  0.970860  ENTAILMENT   \n",
       "1                   a            a  0.997530  0.000801  0.001669     NEUTRAL   \n",
       "2                   a            a  0.997514  0.000847  0.001638     NEUTRAL   \n",
       "3                   a            a  0.997635  0.001245  0.001120     NEUTRAL   \n",
       "4                   a            a  0.997635  0.001192  0.001172     NEUTRAL   \n",
       "\n",
       "  Type  \n",
       "0  ref  \n",
       "1  ref  \n",
       "2  ref  \n",
       "3  ref  \n",
       "4  ref  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_pop_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18d2df7e-6a59-4ebe-822d-f7d7de5e218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_df.to_csv('data/contrast_final.csv', index = None, header=True) \n",
    "fact_pop_df.to_csv('data/factuality_popular_final.csv', index = None, header=True) \n",
    "\n",
    "# cont_df.to_csv('contrast_mask_bertscore.csv', index = None, header=True) \n",
    "# fact_pop_df.to_csv('factuality_popular_mask_bertscore.csv', index = None, header=True) \n",
    "\n",
    "# cont_df.to_csv('contrast_mask_spacysim.csv', index = None, header=True) \n",
    "# fact_pop_df.to_csv('factuality_popular_mask_spacysim.csv', index = None, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b66e35a-818a-47d9-afa6-0cd33e3ab2d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.conda-ds696-project)",
   "language": "python",
   "name": "conda-env-.conda-ds696-project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
