python3 src/experiments.py -r paraphrase-realneut-01 -n "Only change from experiment-paraphrase-summary-01: saving results summ to wandb and run folder name now has run name and TS"
python3 src/experiments.py -r paraphrase-binneut-01 -n "Now trying with binary neutrality values"
python3 src/experiments.py -r paraphrase-binall-01 -n "Now trying with binary treatment of all labels taking ['label', 'neutral] as 'label' "
python3 src/experiments.py -r paraphrase-binreal-01 -n "Now trying with binary treatment of all labels taking ['label', 'neutral] as 'label' but also multiplying by taking max(ent1, ent2), max(cont1, cont2), avg(neut1, neut2) "
python3 src/experiments.py -r paraphrase-binall-02 -n "Now scoring each sentence as cont if it's contradicted by atleast one statement, neutral if neutral to all, and ent otherwise. Individual comparison labels are scored in favour of CONTRADICTION/ENTAILMENT if clashing with NEUTRAL in other direction"
python3 src/experiments.py -r nli-summ-sentpairs-01 -n "Generating (summ, ent) sent_nli pairs now"
python3 src/experiments.py -r paraphrase-binall-summsent-01 -n "Now scoring each sentence by comparing it with the other two summaries in the (summ -> sent) direction."
python3 src/experiments.py -r paraphrase-binall-splitsent-01 -n "Now splitting each complex sent into simple sents before computing NLI metric."
python3 src/experiments.py -r paraphrase-binall-splitsent-02-no-fact -n "Now splitting each complex sent into simple sents before computing NLI metric, wihtout evaluating factuality"

python3 src/experiments.py -r negation-binall-splitsent-01-no-fact -n "Now running negation experiment on base and negated datasets on ref_a, ref_a_neg summaries. All-or-nothing binary treatment of labels. Only contrast, no factuality."
python3 src/experiments.py -r negation-binall-splitsent-01-no-fact-roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli -n "Same as negation-binall-splitsent-01-no-fact but different nli model"

python3 src/experiments.py -r similarity-binall-splitsent-01-no-fact -n "Now running similarity experiment"

python3 src/experiments.py -r rescale-metrics-0-1 -n "Rerunning everything with all metrics rescaled to [0, 1]"

python3 src/experiments.py -r test-local-env-01 -n "Rerunning everything on local environment"

python3 src/experiments.py -r aggregation-change-01-otherentity -n "Rerunning everything but changed aggregation of each sentence to level of other entity before taking a mean"
python3 src/experiments.py -r aggregation-change-02-newentcont -n "Rerunning everything but now computing majority between ent and cont for a single sentence"
python3 src/experiments.py -r aggregation-change-03-both -n "Rerunning everything but now combining changes from aggregation-change-01-otherentity and aggregation-change-02-newentcont"

python3 src/experiments.py -r negation-all-examples-01 -n "Exapnded negation experiment to 48 examples"

python3 src/experiments.py -r only-contrastive-01 -n "Rerunning all experiments with only 2 contrastive summaries"


rm -rf data/results/sentpairs_nli_*
rm -rf data/results/nli_contrast_*
rm -rf data/results/nli_factuality_*

export